---
layout: post
category: research
title: Sketch2Sound
permalink: /sketch2sound-landing/
# image: /assets/img/research/vampnet-hero.png
---

<!-- https://oreillyp.github.io/tria/assets/video/tria_compressed.mp4 -->
<!-- (copilot: embed the video above) -->

<figure>
  <img src="/sketch2sound/figs/hero-figure.png" alt="" style="margin-bottom:2px; max-width: 1200px">
  <!-- <figcaption>Overview of Sketch2Sound. We extract three control signals from any input sonic imitation: loudness, spectral centroid (i.e., brightness) and pitch probabilities. We encode the signals and add them to the latents used as input to a DiT text-to-sound generation system.</figcaption> -->
</figure>

Sketch2Sound is a generative audio model capable of creating high-quality sounds from a set of interpretable time-varying control signals: loudness, brightness, and pitch, as well as text prompts.

**Sketch2Sound can synthesize arbitrary sounds from sonic imitations** (i.e., a vocal imitation or a reference sound-shape). 

Check out our demo video, paper and website: [sketch2sound website](/sketch2sound/)
